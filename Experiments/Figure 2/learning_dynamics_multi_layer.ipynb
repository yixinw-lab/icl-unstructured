{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "674d5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras_nlp.layers import PositionEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a29d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 50\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d96c3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_module(query, key, value, embed_dim, num_head, i):\n",
    "    \n",
    "    # Multi headed self-attention\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_head,\n",
    "        key_dim=embed_dim // num_head,\n",
    "        name=\"encoder_{}/multiheadattention\".format(i)\n",
    "    )(query, key, value, use_causal_mask=True)\n",
    "    \n",
    "    # Add & Normalize\n",
    "    attention_output = layers.Add()([query, attention_output])  # Skip Connection\n",
    "    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "    \n",
    "    # Feedforward network\n",
    "    ff_net = keras.models.Sequential([\n",
    "        layers.Dense(2 * embed_dim, activation='relu', name=\"encoder_{}/ffn_dense_1\".format(i)),\n",
    "        layers.Dense(embed_dim, name=\"encoder_{}/ffn_dense_2\".format(i)),\n",
    "    ])\n",
    "\n",
    "    # Apply Feedforward network\n",
    "    ffn_output = ff_net(attention_output)\n",
    "\n",
    "    # Add & Normalize\n",
    "    ffn_output = layers.Add()([attention_output, ffn_output])  # Skip Connection\n",
    "    ffn_output = layers.LayerNormalization(epsilon=1e-6)(ffn_output)\n",
    "    \n",
    "    return ffn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7afdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoidal_embeddings(sequence_length, embedding_dim):\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2. * i / embedding_dim) for i in range(embedding_dim)]\n",
    "        if pos != 0 else np.zeros(embedding_dim)\n",
    "        for pos in range(sequence_length)\n",
    "    ])\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])  # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2])  # dim 2i+1\n",
    "    return tf.cast(position_enc, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de18fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_element_randomly(my_list, element):\n",
    "    \n",
    "    if len(my_list) > 1:\n",
    "\n",
    "        index = random.randint(0, 2)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        index = 0\n",
    "\n",
    "    new_list = my_list[:(4 * index)] + element + my_list[(4 * index):]\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95bab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 # vocab_size\n",
    "M = 20 # number of random words\n",
    "\n",
    "vocabs = ['word_' + str(i) for i in range(N)] + ['random_' + str(i) for i in range(M)]\n",
    "\n",
    "vocabs_word = ['word_' + str(i) for i in range(N)]\n",
    "\n",
    "vocab_map = {}\n",
    "for i in range(len(vocabs)):\n",
    "    vocab_map[vocabs[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5098e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "for i in vocabs_word:\n",
    "    for j in vocabs_word:\n",
    "        for k in vocabs_word:\n",
    "            if i != j and i != k and j != k:\n",
    "                pairs.append((i,j,k))\n",
    "\n",
    "indicator = np.random.choice([0, 1], size=len(pairs), p=[0.5, 0.5])\n",
    "\n",
    "pairs_train = [pairs[i] for i in range(len(indicator)) if indicator[i] == 1]\n",
    "pairs_test = [pairs[i] for i in range(len(indicator)) if indicator[i] == 0]\n",
    "\n",
    "sentences_train = []\n",
    "sentences_number_train = []\n",
    "sentences_test_a = []\n",
    "sentences_number_test_a = []\n",
    "sentences_test_b = []\n",
    "sentences_number_test_b = []\n",
    "\n",
    "x_masked_train = []\n",
    "y_masked_labels_train = []\n",
    "x_masked_test_a = []\n",
    "y_masked_labels_test_a = []\n",
    "x_masked_test_b = []\n",
    "y_masked_labels_test_b = []\n",
    "\n",
    "for _ in range(25000):\n",
    "\n",
    "    random_words = random.sample(['random_' + str(i) for i in range(M)], 4)\n",
    "\n",
    "    [(a,b,c), (d,e,f)] = random.sample(pairs_train, 2)\n",
    "\n",
    "    temp = [a, b, c, a, d, e, f, d]\n",
    "    temp = insert_element_randomly(temp, random_words)\n",
    "\n",
    "    sentences_train.append(temp)\n",
    "    sentences_number_train.append([vocab_map[i] for i in temp])\n",
    "    x_masked_train.append([vocab_map[i] for i in temp])\n",
    "    y_masked_labels_train.append([vocab_map[i] for i in temp][1:])\n",
    "\n",
    "    random_words = random.sample(['random_' + str(i) for i in range(M)], 4)\n",
    "\n",
    "    [(a,b,c), (d,e,f)] = random.sample(pairs_train, 2)\n",
    "\n",
    "    temp = [a, b, c, b, d, e, f, e]\n",
    "    temp = insert_element_randomly(temp, random_words)\n",
    "\n",
    "    sentences_train.append(temp)\n",
    "    sentences_number_train.append([vocab_map[i] for i in temp])\n",
    "    x_masked_train.append([vocab_map[i] for i in temp])\n",
    "    y_masked_labels_train.append([vocab_map[i] for i in temp][1:])\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(25000):\n",
    "\n",
    "    [(a,b,c), (d,e,f), (g,h,i)] = random.sample(pairs_test, 3)\n",
    "\n",
    "    temp = [a, b, c, a, d, e, f, d, g, h, i, g]\n",
    "\n",
    "    sentences_test_a.append(temp)\n",
    "    sentences_number_test_a.append([vocab_map[i] for i in temp])\n",
    "    x_masked_test_a.append([vocab_map[i] for i in temp])\n",
    "    y_masked_labels_test_a.append([vocab_map[i] for i in temp][1:])\n",
    "\n",
    "    [(a,b,c), (d,e,f), (g,h,i)] = random.sample(pairs_test, 3)\n",
    "\n",
    "    temp = [a, b, c, b, d, e, f, e, g, h, i, h]\n",
    "\n",
    "    sentences_test_b.append(temp)\n",
    "    sentences_number_test_b.append([vocab_map[i] for i in temp])\n",
    "    x_masked_test_b.append([vocab_map[i] for i in temp])\n",
    "    y_masked_labels_test_b.append([vocab_map[i] for i in temp][1:])\n",
    "\n",
    "x_masked_train = np.array(x_masked_train)\n",
    "y_masked_labels_train = np.array(y_masked_labels_train)\n",
    "x_masked_test_a = np.array(x_masked_test_a)\n",
    "y_masked_labels_test_a = np.array(y_masked_labels_test_a)\n",
    "x_masked_test_b = np.array(x_masked_test_b)\n",
    "y_masked_labels_test_b = np.array(y_masked_labels_test_b)\n",
    "\n",
    "perm = np.random.permutation(len(x_masked_train))\n",
    "x_masked_train = x_masked_train[perm]\n",
    "y_masked_labels_train = y_masked_labels_train[perm]\n",
    "\n",
    "x_masked_train = x_masked_train[:,:-1]\n",
    "x_masked_test_a = x_masked_test_a[:,:-1]\n",
    "x_masked_test_b = x_masked_test_b[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "100e8062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  3,  2,  3,  2, 18,  9, 18, 36, 24, 27])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_masked_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "384d96d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  2,  3,  2, 18,  9, 18, 36, 24, 27, 34])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_masked_labels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae5495db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "embed_dim = 100\n",
    "num_heads = 2\n",
    "num_blocks = 5\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "input_layer = layers.Input(shape=(x_masked_train.shape[1],), dtype=tf.int32)  # Input layer\n",
    "\n",
    "embedding_layer = layers.Embedding(M + N, embed_dim, name=\"word_embedding\")(input_layer)  # Embedding layer\n",
    "position_embeddings = PositionEmbedding(sequence_length=len(x_masked_train[0]))(embedding_layer)\n",
    "embedding_layer = embedding_layer + position_embeddings\n",
    "\n",
    "# Transformer blocks with causal masking for next token prediction\n",
    "x = embedding_layer\n",
    "for i in range(num_blocks):\n",
    "    # Apply the causal mask to ensure that each position can only attend to known tokens\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=embed_dim // num_heads\n",
    "    )(x, x, x, use_causal_mask=True)\n",
    "    \n",
    "    x = layers.Add()([x, attention_output])  # Skip Connection\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    ff_net = keras.models.Sequential([\n",
    "        layers.Dense(2 * embed_dim, activation='relu'),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "\n",
    "    # Apply Feedforward network\n",
    "    x = ff_net(x)\n",
    "\n",
    "    # Add & Normalize\n",
    "    x = layers.Add()([attention_output, x]) \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "# Output layer for providing predictions over the vocabulary\n",
    "predict_layer = layers.Dense(M + N, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=predict_layer)  # Model definition\n",
    "model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile the model\n",
    "\n",
    "# Reshape the target data to have an extra dimension\n",
    "y_masked_labels_train_reshaped = y_masked_labels_train.reshape(y_masked_labels_train.shape[0], \n",
    "                                                               y_masked_labels_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26d8d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_subset_a = x_masked_test_a[np.random.choice(x_masked_test_a.shape[0], size=500, replace=False)]\n",
    "x_test_subset_b = x_masked_test_b[np.random.choice(x_masked_test_b.shape[0], size=500, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99cb5822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49/49 [==============================] - 20s 269ms/step - loss: 3.6608 - accuracy: 0.0336\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 14s 279ms/step - loss: 3.5898 - accuracy: 0.0358\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 14s 281ms/step - loss: 3.0887 - accuracy: 0.0487\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 275ms/step - loss: 3.0431 - accuracy: 0.0497\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 14s 278ms/step - loss: 3.0448 - accuracy: 0.0516\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 14s 282ms/step - loss: 3.0481 - accuracy: 0.0503\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 14s 285ms/step - loss: 3.0297 - accuracy: 0.0572\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 14s 282ms/step - loss: 2.9072 - accuracy: 0.0956\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 14s 284ms/step - loss: 2.7109 - accuracy: 0.1287\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 14s 280ms/step - loss: 2.6425 - accuracy: 0.1357\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 14s 287ms/step - loss: 2.6307 - accuracy: 0.1373\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 14s 283ms/step - loss: 2.6213 - accuracy: 0.1392\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 14s 286ms/step - loss: 2.6149 - accuracy: 0.1415\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 14s 283ms/step - loss: 2.6095 - accuracy: 0.1422\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 14s 281ms/step - loss: 2.6016 - accuracy: 0.1448\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 14s 284ms/step - loss: 2.5946 - accuracy: 0.1456\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 14s 283ms/step - loss: 2.5841 - accuracy: 0.1484\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 14s 284ms/step - loss: 2.5731 - accuracy: 0.1496\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 14s 279ms/step - loss: 2.5626 - accuracy: 0.1506\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 14s 278ms/step - loss: 2.5498 - accuracy: 0.1522\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 14s 286ms/step - loss: 2.5396 - accuracy: 0.1524\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 14s 277ms/step - loss: 2.5303 - accuracy: 0.1538\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 14s 277ms/step - loss: 2.5226 - accuracy: 0.1541\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 274ms/step - loss: 2.5152 - accuracy: 0.1548\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 273ms/step - loss: 2.5083 - accuracy: 0.1559\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 270ms/step - loss: 2.5038 - accuracy: 0.1567\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.4990 - accuracy: 0.1575\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.4950 - accuracy: 0.1577\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.4915 - accuracy: 0.1590\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.4868 - accuracy: 0.1596\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.4852 - accuracy: 0.1600\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 273ms/step - loss: 2.4820 - accuracy: 0.1614\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 272ms/step - loss: 2.4792 - accuracy: 0.1618\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 269ms/step - loss: 2.4766 - accuracy: 0.1624\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 269ms/step - loss: 2.4729 - accuracy: 0.1635\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 269ms/step - loss: 2.4716 - accuracy: 0.1641\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.4693 - accuracy: 0.1655\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.4666 - accuracy: 0.1654\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.4643 - accuracy: 0.1670\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.4610 - accuracy: 0.1682\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.4599 - accuracy: 0.1686\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.4574 - accuracy: 0.1702\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.4558 - accuracy: 0.1708\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.4534 - accuracy: 0.1720\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 2.4509 - accuracy: 0.1736\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.4497 - accuracy: 0.1743\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.4468 - accuracy: 0.1766\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.4449 - accuracy: 0.1774\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.4409 - accuracy: 0.1807\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.4367 - accuracy: 0.1859\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.4161 - accuracy: 0.2017\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.3973 - accuracy: 0.2095\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.3883 - accuracy: 0.2134\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3825 - accuracy: 0.2150\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.3781 - accuracy: 0.2170\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.3768 - accuracy: 0.2183\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3729 - accuracy: 0.2196\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.3692 - accuracy: 0.2211\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.3665 - accuracy: 0.2223\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3644 - accuracy: 0.2234\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.3627 - accuracy: 0.2246\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.3600 - accuracy: 0.2255\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.3573 - accuracy: 0.2273\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3540 - accuracy: 0.2290\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3520 - accuracy: 0.2295\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.3516 - accuracy: 0.2311\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3476 - accuracy: 0.2320\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3444 - accuracy: 0.2330\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.3414 - accuracy: 0.2347\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.3411 - accuracy: 0.2347\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.3386 - accuracy: 0.2366\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.3346 - accuracy: 0.2382\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.3314 - accuracy: 0.2392\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.3284 - accuracy: 0.2410\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.3266 - accuracy: 0.2416\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.3245 - accuracy: 0.2427\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.3207 - accuracy: 0.2443\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.3179 - accuracy: 0.2455\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.3146 - accuracy: 0.2469\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.3126 - accuracy: 0.2474\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.3109 - accuracy: 0.2490\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 12s 254ms/step - loss: 2.3076 - accuracy: 0.2497\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.3039 - accuracy: 0.2514\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.3009 - accuracy: 0.2527\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.2989 - accuracy: 0.2536\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.2953 - accuracy: 0.2547\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2925 - accuracy: 0.2561\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.2899 - accuracy: 0.2571\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 255ms/step - loss: 2.2870 - accuracy: 0.2587\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.2842 - accuracy: 0.2599\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.2812 - accuracy: 0.2610\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.2797 - accuracy: 0.2610\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.2758 - accuracy: 0.2628\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.2734 - accuracy: 0.2638\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.2697 - accuracy: 0.2655\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.2671 - accuracy: 0.2661\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2647 - accuracy: 0.2666\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.2605 - accuracy: 0.2689\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.2567 - accuracy: 0.2699\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.2562 - accuracy: 0.2702\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.2535 - accuracy: 0.2713\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.2488 - accuracy: 0.2727\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.2462 - accuracy: 0.2741\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2426 - accuracy: 0.2749\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2414 - accuracy: 0.2760\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.2382 - accuracy: 0.2774\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2348 - accuracy: 0.2784\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2325 - accuracy: 0.2791\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2277 - accuracy: 0.2809\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.2259 - accuracy: 0.2816\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.2232 - accuracy: 0.2826\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2202 - accuracy: 0.2836\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.2179 - accuracy: 0.2840\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.2144 - accuracy: 0.2853\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.2131 - accuracy: 0.2867\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 269ms/step - loss: 2.2102 - accuracy: 0.2875\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.2078 - accuracy: 0.2878\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.2045 - accuracy: 0.2886\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 12s 254ms/step - loss: 2.2002 - accuracy: 0.2909\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1987 - accuracy: 0.2915\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.1966 - accuracy: 0.2927\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1944 - accuracy: 0.2929\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.1905 - accuracy: 0.2939\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1864 - accuracy: 0.2955\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1855 - accuracy: 0.2959\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1829 - accuracy: 0.2974\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1809 - accuracy: 0.2976\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.1773 - accuracy: 0.2986\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1733 - accuracy: 0.3002\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1730 - accuracy: 0.3001\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1717 - accuracy: 0.3012\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.1698 - accuracy: 0.3017\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1665 - accuracy: 0.3020\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1624 - accuracy: 0.3039\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1615 - accuracy: 0.3046\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1596 - accuracy: 0.3051\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 2.1582 - accuracy: 0.3051\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1539 - accuracy: 0.3069\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1494 - accuracy: 0.3088\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1500 - accuracy: 0.3081\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1476 - accuracy: 0.3097\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1448 - accuracy: 0.3097\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.1440 - accuracy: 0.3098\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1373 - accuracy: 0.3124\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1379 - accuracy: 0.3122\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 2.1361 - accuracy: 0.3135\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1342 - accuracy: 0.3135\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.1334 - accuracy: 0.3136\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.1274 - accuracy: 0.3159\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.1283 - accuracy: 0.3154\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.1263 - accuracy: 0.3166\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.1235 - accuracy: 0.3174\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.1214 - accuracy: 0.3173\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1165 - accuracy: 0.3194\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1194 - accuracy: 0.3184\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.1176 - accuracy: 0.3195\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.1129 - accuracy: 0.3205\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1109 - accuracy: 0.3211\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.1085 - accuracy: 0.3223\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.1087 - accuracy: 0.3214\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1081 - accuracy: 0.3222\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.1032 - accuracy: 0.3239\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.1018 - accuracy: 0.3242\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0972 - accuracy: 0.3262\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0970 - accuracy: 0.3253\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.0994 - accuracy: 0.3261\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0926 - accuracy: 0.3273\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0933 - accuracy: 0.3272\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.0895 - accuracy: 0.3285\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0875 - accuracy: 0.3283\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 2.0887 - accuracy: 0.3293\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.0852 - accuracy: 0.3300\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0853 - accuracy: 0.3298\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0807 - accuracy: 0.3314\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0825 - accuracy: 0.3297\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0810 - accuracy: 0.3315\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0777 - accuracy: 0.3328\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0755 - accuracy: 0.3328\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0722 - accuracy: 0.3344\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0721 - accuracy: 0.3339\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0700 - accuracy: 0.3351\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0677 - accuracy: 0.3355\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0678 - accuracy: 0.3355\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.0658 - accuracy: 0.3364\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0643 - accuracy: 0.3366\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 2.0627 - accuracy: 0.3374\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0610 - accuracy: 0.3378\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.0601 - accuracy: 0.3381\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.0576 - accuracy: 0.3390\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.0576 - accuracy: 0.3383\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.0544 - accuracy: 0.3401\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 2.0538 - accuracy: 0.3407\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0525 - accuracy: 0.3403\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0500 - accuracy: 0.3416\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0483 - accuracy: 0.3418\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.0485 - accuracy: 0.3412\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 2.0463 - accuracy: 0.3427\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 2.0455 - accuracy: 0.3431\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 2.0412 - accuracy: 0.3444\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0435 - accuracy: 0.3432\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0424 - accuracy: 0.3438\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0406 - accuracy: 0.3448\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0380 - accuracy: 0.3450\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0349 - accuracy: 0.3468\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0348 - accuracy: 0.3464\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0342 - accuracy: 0.3464\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0332 - accuracy: 0.3471\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0313 - accuracy: 0.3469\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0283 - accuracy: 0.3488\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0308 - accuracy: 0.3472\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 2.0269 - accuracy: 0.3488\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0240 - accuracy: 0.3501\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 268ms/step - loss: 2.0224 - accuracy: 0.3505\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0228 - accuracy: 0.3504\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0209 - accuracy: 0.3510\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0214 - accuracy: 0.3507\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0199 - accuracy: 0.3511\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 2.0186 - accuracy: 0.3518\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0191 - accuracy: 0.3509\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 2.0174 - accuracy: 0.3514\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 2.0149 - accuracy: 0.3525\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0144 - accuracy: 0.3531\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0127 - accuracy: 0.3530\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0122 - accuracy: 0.3534\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.0112 - accuracy: 0.3535\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0110 - accuracy: 0.3538\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0102 - accuracy: 0.3539\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0052 - accuracy: 0.3556\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 2.0030 - accuracy: 0.3567\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 2.0073 - accuracy: 0.3545\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 2.0054 - accuracy: 0.3561\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 2.0029 - accuracy: 0.3571\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 2.0002 - accuracy: 0.3575\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9987 - accuracy: 0.3580\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 12s 255ms/step - loss: 2.0001 - accuracy: 0.3573\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9976 - accuracy: 0.3579\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9963 - accuracy: 0.3591\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9939 - accuracy: 0.3592\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 255ms/step - loss: 1.9937 - accuracy: 0.3596\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9990 - accuracy: 0.3571\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9956 - accuracy: 0.3589\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9939 - accuracy: 0.3589\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9906 - accuracy: 0.3608\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9896 - accuracy: 0.3607\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 255ms/step - loss: 1.9907 - accuracy: 0.3600\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9894 - accuracy: 0.3607\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9850 - accuracy: 0.3619\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9832 - accuracy: 0.3628\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9835 - accuracy: 0.3626\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9858 - accuracy: 0.3617\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9852 - accuracy: 0.3615\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9847 - accuracy: 0.3624\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9830 - accuracy: 0.3625\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9804 - accuracy: 0.3638\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 255ms/step - loss: 1.9809 - accuracy: 0.3631\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9793 - accuracy: 0.3637\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9791 - accuracy: 0.3638\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9773 - accuracy: 0.3650\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9762 - accuracy: 0.3652\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9745 - accuracy: 0.3650\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9770 - accuracy: 0.3644\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9734 - accuracy: 0.3664\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9744 - accuracy: 0.3653\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9724 - accuracy: 0.3657\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9716 - accuracy: 0.3657\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9746 - accuracy: 0.3653\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 12s 254ms/step - loss: 1.9722 - accuracy: 0.3665\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9706 - accuracy: 0.3666\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9668 - accuracy: 0.3676\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9676 - accuracy: 0.3676\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9662 - accuracy: 0.3679\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9657 - accuracy: 0.3688\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9640 - accuracy: 0.3683\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9644 - accuracy: 0.3685\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9651 - accuracy: 0.3678\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9654 - accuracy: 0.3676\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9650 - accuracy: 0.3686\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9627 - accuracy: 0.3690\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9602 - accuracy: 0.3699\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9626 - accuracy: 0.3689\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9611 - accuracy: 0.3696\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9563 - accuracy: 0.3711\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9585 - accuracy: 0.3700\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9576 - accuracy: 0.3714\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9566 - accuracy: 0.3708\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9570 - accuracy: 0.3711\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9570 - accuracy: 0.3711\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9524 - accuracy: 0.3722\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 255ms/step - loss: 1.9522 - accuracy: 0.3724\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9537 - accuracy: 0.3713\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9538 - accuracy: 0.3725\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.9536 - accuracy: 0.3724\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9543 - accuracy: 0.3712\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9491 - accuracy: 0.3733\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9528 - accuracy: 0.3720\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9503 - accuracy: 0.3734\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9499 - accuracy: 0.3734\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9502 - accuracy: 0.3727\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9448 - accuracy: 0.3741\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9452 - accuracy: 0.3735\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9468 - accuracy: 0.3736\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.9491 - accuracy: 0.3733\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9475 - accuracy: 0.3735\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9421 - accuracy: 0.3752\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9463 - accuracy: 0.3742\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9431 - accuracy: 0.3750\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9428 - accuracy: 0.3752\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9431 - accuracy: 0.3749\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 275ms/step - loss: 1.9407 - accuracy: 0.3754\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 1.9397 - accuracy: 0.3761\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9393 - accuracy: 0.3764\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 1.9393 - accuracy: 0.3763\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 1.9360 - accuracy: 0.3772\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9359 - accuracy: 0.3775\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9375 - accuracy: 0.3765\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9358 - accuracy: 0.3773\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9344 - accuracy: 0.3783\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9350 - accuracy: 0.3774\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9345 - accuracy: 0.3778\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9361 - accuracy: 0.3771\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9358 - accuracy: 0.3771\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9340 - accuracy: 0.3781\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9299 - accuracy: 0.3794\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9294 - accuracy: 0.3794\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9298 - accuracy: 0.3793\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9306 - accuracy: 0.3790\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9286 - accuracy: 0.3791\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9271 - accuracy: 0.3801\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9266 - accuracy: 0.3803\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9279 - accuracy: 0.3794\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9286 - accuracy: 0.3797\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9295 - accuracy: 0.3794\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9267 - accuracy: 0.3807\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9239 - accuracy: 0.3814\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9267 - accuracy: 0.3802\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 1.9236 - accuracy: 0.3810\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9225 - accuracy: 0.3816\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9219 - accuracy: 0.3822\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9212 - accuracy: 0.3821\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9223 - accuracy: 0.3812\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9210 - accuracy: 0.3820\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9203 - accuracy: 0.3824\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9192 - accuracy: 0.3828\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9174 - accuracy: 0.3841\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9215 - accuracy: 0.3816\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9203 - accuracy: 0.3818\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9169 - accuracy: 0.3837\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9188 - accuracy: 0.3828\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9208 - accuracy: 0.3821\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 1.9178 - accuracy: 0.3829\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.9204 - accuracy: 0.3820\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9164 - accuracy: 0.3836\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9138 - accuracy: 0.3841\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9124 - accuracy: 0.3843\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9139 - accuracy: 0.3836\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9179 - accuracy: 0.3828\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9187 - accuracy: 0.3825\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9148 - accuracy: 0.3836\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9082 - accuracy: 0.3866\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9119 - accuracy: 0.3842\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9118 - accuracy: 0.3849\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9157 - accuracy: 0.3840\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9149 - accuracy: 0.3839\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9085 - accuracy: 0.3862\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9090 - accuracy: 0.3859\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9086 - accuracy: 0.3855\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9103 - accuracy: 0.3851\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9096 - accuracy: 0.3854\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9072 - accuracy: 0.3861\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9101 - accuracy: 0.3849\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9099 - accuracy: 0.3860\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9082 - accuracy: 0.3861\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 1.9111 - accuracy: 0.3852\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 270ms/step - loss: 1.9048 - accuracy: 0.3876\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.9076 - accuracy: 0.3859\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9074 - accuracy: 0.3860\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9047 - accuracy: 0.3872\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.9037 - accuracy: 0.3867\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.8976 - accuracy: 0.3897\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 1.9043 - accuracy: 0.3869\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9048 - accuracy: 0.3872\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9042 - accuracy: 0.3877\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9025 - accuracy: 0.3877\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.8968 - accuracy: 0.3900\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.9012 - accuracy: 0.3878\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.9029 - accuracy: 0.3872\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 261ms/step - loss: 1.9040 - accuracy: 0.3870\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.8993 - accuracy: 0.3877\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 1.8976 - accuracy: 0.3890\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.8966 - accuracy: 0.3896\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 259ms/step - loss: 1.8988 - accuracy: 0.3888\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.9006 - accuracy: 0.3885\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 257ms/step - loss: 1.8973 - accuracy: 0.3890\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 1.8970 - accuracy: 0.3900\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.8980 - accuracy: 0.3894\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 1.8986 - accuracy: 0.3890\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 1.8995 - accuracy: 0.3884\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 13s 263ms/step - loss: 1.8939 - accuracy: 0.3908\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 1.8938 - accuracy: 0.3905\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 1.8974 - accuracy: 0.3896\n"
     ]
    }
   ],
   "source": [
    "acc_a_list = []\n",
    "acc_a_oo_list = []\n",
    "prob_a_list = []\n",
    "\n",
    "acc_b_list = []\n",
    "acc_b_oo_list = []\n",
    "prob_b_list = []\n",
    "\n",
    "for _ in range(80):\n",
    "    \n",
    "    history = model.fit(x_masked_train, y_masked_labels_train_reshaped, epochs=5, batch_size=batch_size)\n",
    "    \n",
    "    acc_a = []\n",
    "    acc_a_oo = []\n",
    "    prob_a = []\n",
    "\n",
    "    for sentence_number in x_test_subset_a:\n",
    "        temp = keras.backend.function(inputs = model.layers[0].input, outputs = model.layers[-1].output) \\\n",
    "            (np.array(sentence_number).reshape(1,len(sentence_number)))\n",
    "        temp = temp[:,-1,:]\n",
    "        acc_a.append(1 if temp.argmax() == sentence_number[-3] else 0)\n",
    "        acc_a_oo.append(1 if temp.argmax() == sentence_number[-3] or temp.argmax() == sentence_number[-2] else 0)\n",
    "        prob_a.append(temp[0][sentence_number[-3]])\n",
    "\n",
    "    acc_b = []\n",
    "    acc_b_oo = []\n",
    "    prob_b = []\n",
    "\n",
    "    for sentence_number in x_test_subset_b:\n",
    "        temp = keras.backend.function(inputs = model.layers[0].input, outputs = model.layers[-1].output) \\\n",
    "            (np.array(sentence_number).reshape(1,len(sentence_number)))\n",
    "        temp = temp[:,-1,:]\n",
    "        acc_b.append(1 if temp.argmax() == sentence_number[-2] else 0)\n",
    "        acc_b_oo.append(1 if temp.argmax() == sentence_number[-2] or temp.argmax() == sentence_number[-3] else 0)\n",
    "        prob_b.append(temp[0][sentence_number[-2]])\n",
    "        \n",
    "    acc_a_list.append(np.mean(acc_a))\n",
    "    acc_a_oo_list.append(np.mean(acc_a_oo))\n",
    "    prob_a_list.append(np.mean(prob_a))\n",
    "\n",
    "    acc_b_list.append(np.mean(acc_b))\n",
    "    acc_b_oo_list.append(np.mean(acc_b_oo))\n",
    "    prob_b_list.append(np.mean(prob_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7cc6de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzQUlEQVR4nO2deZgdVZn/P2930ul0FkMWGMjSiQNIAo9EjDjOCIMwC4gEFCNL6wAyZlh0dNARnYwOM0N+M+IwgooTwyaSRtRBFh22EQYFESXIIiGALNlYs4F0ukOWfn9/nLrpyu271O2+dW913+/neeq5VaeqTr11btX5nvOepczdEUII0bg01dsAIYQQ9UVCIIQQDY6EQAghGhwJgRBCNDgSAiGEaHAkBEII0eBICIQYYpjZKjP7syrF9T0zO2GA555uZvdVw44KrzvKzJ40sz1rfe3hioSgATCze8xss5mNqrctIjuY2duBg4Gbo+0jzKzXzLpiy2n1tbI/7v4mcBVwfr1tGS5ICIY5ZjYTOAxwYH6Nrz2iltdLm+F2P8DfAJ2++6jSF919bGy5pl7GFSL2H1wHnKbCTXWQEAx//gp4APgOsFvpzsymm9mPzGy9mW00s2/G9n3CzFaa2Rtm9oSZHRKFu5ntGzvuO2Z2YbR+hJmtM7Pzzexl4Goz28PMfhJdY3O0Pi12/kQzu9rMXoz23xSFP25mx8WOG2lmG8xsbqGbjOx9xsw2mdktZrZPFL7EzP4j79ibzey8aH0fM7shsu95M/vb2HEXmNl/m9kyM/s9cHqB644ys/8wszVm9kp0vdF56fEPke2rzKwjdu5bzOy70bVXm9k/mllTbH/B/yBirpk9Zmavm9n3zaw1OmdylMavRWlxbzzOPI4BflZkX8WY2aVmttbMfm9mD5nZYVH4H5hZt5lNih37zui+R0bbH4/udbOZ3WFm7bFj3czONbPfAb8DcPd1wGbgj6plf0Pj7lqG8QI8A5wDvBPYDuwVhTcDjwJfA8YArcB7o30LgBeAdwEG7Au0R/sc2DcW/3eAC6P1I4AdwFeAUcBoYBJwItAGjAN+CNwUO/9/gO8DewAjgT+Nwj8PfD923PHAb4vc45HABuCQ6LrfAH4e7TscWAtYtL0H0APsQygIPQR8GWgB3go8B/xldOwFUZqdEB07usC1LwFuASZG9/dj4N/y0uM/I7v+FNgCvC3a/12CW2YcMBN4GjgzwX+wCvh1dA8TgZXAWdG+fwOWRGk5klAbtAJ2j4n+yymxsCOAbcArwPNEz0aJZ+t04L7Y9kej/3sE8FngZaA12ncrcHbs2K8B34jWTyA8p7Ojc/8RuD92rAP/G93r6Fj4LcDf1vsdGw5L3Q3QkuKfC++NMrLJ0faTwN9F6+8B1gMjCpx3B/DpInGWE4JtuZe/yPlzgc3R+t5AL7BHgeP2Ad4Axkfb/w18vkicVwIXxbbHRvc9M8pE1wCHR/s+Adwdrb8bWJMX1xeBq6P1C4gEpch1jZCx/2Es7D3A87H02BHPTIEfAF8iCPGbwJzYvr8B7knwH6wCPhrbvghYEq3/C0Fc9i1md3Tc1Oi/bI2F/QEwhyB6s4CfA98uEcfpxISgwP7NwMHR+knAL6L1ZoJIHBpt30YkgNF2E9DN7oWPIwvE3wl8uR7v1nBb5Boa3pwG3OnuG6Lt6+hzD00HVrv7jgLnTQeeHeA117v71tyGmbWZ2bcj18fvCZnLBDNrjq6zyd0350fi7i8CvwBONLMJBDdGZ5Fr7gOsjp3bBWwEpnrIMa4HTol2nxqLpx3YJ3KjvGZmrwH/AOwVi3ttiXudQqjpPBQ7//YoPMdmd98S214d2TuZUAtZnbdvarRe7j94ObbeTRA/gK8SStd3mtlzZvaFIue/Fv2OywW4+8vu/oS797r784Ra2YcBzOww62tAXlEoQjP7bOTeeT1Ki7dE9wlBnOaY2VuBPwded/dfR/vagUtjabiJILJTY9EX+h/Gxe5DDILh1vglIiI/9UeA5shfD8E9McHMDia8WDPMbEQBMVgL/GGRqLsJmV+OPwDWxbbzp7P9LPA24N3u/nLk43+Y8KKvBSaa2QR3f63Ata4B/prwnP7S3V8oYtOLhMwEADMbQ3BR5I7/HiFj/HdCLeCDsft83t33KxJvofuJs4HgZjqwhG17mNmYmBjMAB6Pzt0e2f1EbF8unlL/QXFj3d8gpPlnzexA4P/M7EF3vyvvuC1m9iywP6FmWDA6wv+Eu99Ln9j0I2oPOB84Cljh7r1mtjl2/lYz+wHQARwAXBs7fS2w2N2LCX3OlnxmAxeXOEckRDWC4csJwE5CVX9utMwG7iU0IP8aeAn4dzMbY2atZvYn0blXAJ+LGvTMzPaNNd49ApxqZs1mdjTB712KcYTM8jUzmwj8U26Hu79EcAt8y0Kj8kgzOzx27k0Ev/+nCf70YlwHnGFmcy30Ivl/wK/cfVV0nYcJmd0VwB0x0fk18HsLjdujo3s6yMzeVeaecvb3ApcDX7OoT7uZTTWzv8w79J/NrCXKLD8A/NDddxLcRIvNbFyUvucBy6JzSv0HRTGzD0THGvB7wjOws8jhtxL7/yw0bs+Irjcd+HeirqUJGEdwg60HRpjZl4Hxecd8l+BOmh+7TwhtGl+MhCvXiL6g1MXMbCqhzeCBhPaJEkgIhi+nEXzda6Iq/8vu/jLwTUKpzIDjCI2Qawil+pMA3P2HwGJCBvsGIUOeGMX76ei816J4bipjxyWERuMNhJf29rz9HyOUjJ8EXgU+k9vh7j3ADQR/9Y+KXSAq7X4pOvYlQkn65LzDvgf8WXRPufN2Rvcyl9A4uoGQAb+lzD3FOZ/ginkgcn39lFADyvEywVf+IsEldZa7Pxnt+xShjeE54L7Itqsi20r9B6XYL7KhC/gl8C13v6fIsUuBjkg0IIjuLyOb7ifUXP62yLn53EEQ9acJLq6t5Llz3P0XhDah3+REOgq/kdDB4PooDR8nuAJLcSpwjYcxBWKQ5HpSCJFJopLl/u7+0XrbUilmdgSwzN2nlTm0bpjZdcAP3P2mGl3vbuA6d79iEHGMIvR4O9zdX62acQ2M2ghEZolcSWcSag0iBdz91FpdK3K5HULoCjxgolrAAVUxSgByDYmMYmafILgWbnP3n9fbHjE4zOwagsvqM1GDtsgQcg0JIUSDoxqBEEI0OEOujWDy5Mk+c+bMepshhBBDioceemiDu08ptG/ICcHMmTNZvnx5vc0QQoghhZmtLrZPriEhhGhwJARCCNHgSAiEEKLBkRAIIUSDIyEQQogGR0IghBA1prMTZs6Epqbw21lqAu4aICEQQogUKJbZd3bCwoWwejW4h9+FC+srBhKCBiJrpRAhhiuFMvuPfQzM4LTToLt79+O7u2HRovrYChKChiGLpRAxNKi0ANGoBY74fRfK7HPTuu0s8pmgNWtSNa809f5ocqXLO9/5TheV097uHh7F3Zf29npbJrLMsmXubW27PzNtbSG8GscnuX57u7tZ+M2Pp9z+Wl2r0H1XuqT9LgLLvUi+WveMvdJFQlCcUg+qWeGHz6xe1g4NBpPRVDOTqjU52yvNtIqd09xceQZbKHMdOdJ90qRw7KRJ7i0t1RGdcgJWzpbm5sGJALjvsUdfGpx9dvWfHQnBECb/JSn2gJR7kPfZp7IXupYlsUrvuZovSaWlvPjLX+raAzl3KJVu4wWIeFxJMrxyGWwunoFmrqVEpxjlasylRHGgS87Ot7ylsjQbKBKCIUqSFzL3gJQriTU1JX+4BlI6qsaDmvSey91H0gy13H0kefmL3Xel5w7EBVNJRl7JtZLYnssgB+oSyT2X1ShJl1ryxbdYIaKUiCUVuGL3WSiOStM7nmYDLSRICIYoSR+QpKWx5ubwUoD72LHFH6aBlo6q4eMcaMkr95IUchcUK4mXu4+kGUCh+6703ErSdKAZedJrJbH9oosG939lZcmlW7EaczXizv1nlbptk8adFAnBECXpA2KW/EFub3d///vd3/a2yq+bcweUKz0Nxpdey5e/3H1Om5Y8zvz7nj49+XlJ0zRXmi12XE4My11vMPunTQtC29KSLK60S/zVWqr17FXTLVVuqbTgJSEYokyZUtkDmPSB/4//COvr1hW+7owZpR+8wbhMcsTdWbUSgKQvf+5lHjGi8jhztY9KM45CrrssLbn/c9my/jWuUs9KNXrTJK3tDVZ0cjXmJAKXdkN1kqXSjh4SgiFEfum4kkwy/iAXeyna291/85uwfu21ha9dLO7cQ37NNcnsKtUQPdjMoVZLPE0LvfxJXlYY2Ln1XgqVbgdSCIg/08WeyyS+9Py40uzCmcRVl2bjfrwto9S7XAkSgiFCkp4m5dwDpUpiuZdq587QVe2MM0pfO/dSjh8ffn/3u3Ds1VeH7SlTyrs0CpG0Kpyk11A1XA/lGi6LvfyVZi5JM8Rq1pAG4woq9P8N1i2YpCF7MJlr/PyBCncSO2tJtWyREAwRKmkwTDIuoNRL9aEPuX9q4jLvnREOWNvc7qewrOC1X3wxvFBnn+2+Y4f7fvu5v+Md7r29pe2OlyjjmXclmWc5BtLXvFiaVTrWohJBq/T/q8RvXE7AkjQen8Iyf55234n584RnodB/UI2OArUcX1GspJ3kucvSOJBq2CIhyDBJSpiFMpLBvpC3/9Uy72L3HLSLtn5ikLv2EUfsfp1Pf3r3e6imq6fS0k7SPvPlXv5K0zTpfQ8kQ62k6/Bgu4vee3bhZ+Hes/v/CVkqKQ+G4XIflSAhyCiDyUgG+yC/uXd7wYs9T3u/ay9b5t7aWvpaSdwe8SW/BHpqJEBplrzSGB9RzhUx0LEa+XGX6gNf6NhiYlhwf4UKmKWS8mAYLveRFAlBRhls75t7z17ma5tDZrq2ub1gCa4YvUWqIDuxfteutKRczv1zCv1LoNtbalMcG1SGWYX44+T/fyuPKjNkOq2cq1KfmKg9VfjvJQQZJUnD271nF3kABlslKJK7r21uTzzqcqC+8+cpckCl3SCySNIXNkl1MK2JdfKZOrWy/2O4FKWHyn1UyY8lIcgoZef/KdUSWizzSJiZ3nv2Mt/B7p3Xi/mFq+0730kdS6DVrhIM1DdUSWtwuWWwVZdqzj8yVBhK91GNFnqXEGSK+PtXqKS927M4kMwiYWa6//Ruf5MR/jrjvBf8jaihuFrtEcX82yPY7j20Fra9WjWCYpl5tRsJKm3kGUjf06RLJZlYIbvj8480N4fBIoWoUqZUN5L2HMgSVXLdSQgyQqH3b8SI3ccJ7OYKGkiGkHCM+9Hc5g7+F9zuV3KGb+YtPoJtRZ+tQdei81/AYsN2B1tFH0wtqtJ+sJUM565216pB/PclM/P/+Z+wft11hc+tRqZUL5dMkv8gaf/rWrL33qWf24RICDJC2cJUDfthXjnu095Nq7fS7cdxszv4Ufxv8WdrMC9FpZlz0ikjK0nkJC9/mnNd1HrSnVJdkEqlw86d7vvv7/6ud/UNFIlTbBKlpJlSqWch7Qw3ybNRqv9uPVxHvb3uBxxQ0btdDAlBRihbmBqM37jCceiv7f02v6PpaAf3Vrq9izb/rxHnFn62UmqY9vb2gd1zqWsPJDOv94Q/hQSv1MQ6ld5X0iG2uWflssvC9l579Z2fy6hHjSp87te/PrhnIT89cvYMNuOt1B23ZElpO+PvUzVrDKX6CoP74Yer11B8GcpCUOjZOoXQhTDRXAClGiMrqbI/95w7+IMfu3TXs3Xb6A/6lj2mFi4FDuSlSDKUuFhDSZKlWAl04sSBxVetpdLMulRJupK2jsEucXG98spkz6JZ6PHQ1OQ+enSyTKrS/3swpfBK0innfhk7NtnozmrWGJLYWYXaiIQgI+T/34X605fNLIplDsUy66am/sd+61th31NP9cV7zTUh7MEH+xteTmQGmjENtEYQv3Z+muT2JYmj3IQ/Sd05hXzzSWwYbCZXaVtFsXTMz7wrdaGMHJn8vor5u5M+/9VOl/jw7CTTzZZrTxpIl9uk78AgG7IlBBli2bI+D8Ta5vbqZRaVlCrmz3efNWv30v+GDeEhHT8+uciUeymSvoADFZFi9520/301BK7S7qGD/czUQP/7SjKWJCJWblKkYnEffHDldiZtiK4kHZI+4/nnJJ2nupLeakkLLoPsXi0hyBA7dwYh+Md/9GQjyiptlC1XGpoxw33MmOC6yT8330deqrTU0lL5g1zsvsr1xS+UmSYVqfz4KxG4QucmbbiudWPjQEvChaikRlCJS/Kuu8K+U06p7P9O+n8krRkVEqly7+Lo0cmf8fw0rlZBSjWC4SMEmzeHVP/P//TKS1OVUC5znjIlWfW0vd29qyu8CG1tId6WFvfJk923bQvnFvuSzUDvq9TLnvvSd7mSWZLSU9qZdZa6SVbSM6dcybqS72Lm4ss9I83NYR7z/Ovl4sn/T83cv/OdZHZVkjnnU+4+kj7j+UspcYrXPMt1VFAbwfASgmefDal+9dWebkaUpJSRpHpq5n755WH93nvDsT/5Sewm3P0jHxn4C1gp3/1ust49AxWdevUVrzaDva/8WloxESmWOU+YUPlo6/zr5j7Rl4troG0hSdxxg3HfDLbDwz33hO2JEwfWZTohdRMC4GjgKeAZ4AsF9r8F+DHwKLACOKNcnENdCB58MKT6zTdHAXFfdT38xuWqpzNmuM+d6/72t/e1KfT2huNHjOizfdascGyKD3JJO9MQHZGMeOa9xx6VZYLl4h1sl95KR1xX2qA70HayuHvz/e8PotfdnTDBB0ZdhABoBp4F3gq0RJn9nLxj/gH4SrQ+BdgEtJSKd6gLwZ13hlTPFa7dPfTN/vznq3+xpIOIcseWEo78z5nl9ycfPbo2mW+121VEdUmaISZx3Q20R1mtGuTLTU9SbJkwIfzeeaf7Y4+F9X/5l+rYWYJ6CcF7gDti218Evph3zBeBbwEGzIpqDk2l4h3qQnD99SHVV6yIAnbsCAEXXJDuhStpGC10XDyjT7Ntoxr3IepHUjdJkv9rIC6XWjXIFxKZJA327e3uW7e677lnXwcMs76BbClSLyH4MHBFbPtjwDfzjhkH/B/wEtAFHFskroXAcmD5jBkz0kyr1Ml14X/xxSigqysEfOUr6V64kvaIcpltJT1F6nkfovZU03WXpAtuWi7IwVLqOS1Uo67BM1wvIVhQQAi+kXfMh4GvRTWCfYHngfGl4h3qNYILLwyp3tMTBaxfHwK+8Y30L560AbFcRl/vUvlwbeAdDgy2x1K5uIaS6A+m23IKZNk19D/AYbHtu4FDS8U71IXgvPPCs7yL1avD33DFFXWzqR/lHtSh/oKKdKmmUA9H0a9TjbqUEDSRHg8C+5nZLDNrAU4Gbsk7Zg1wFICZ7QW8DXguRZvqzubNMHFiLKCnJ/yOHl0XewqyeDG0te0e1tYWwgE6OmDpUmhvB7Pwu3RpCBeiowNWrYLe3vA7mOeimnFlhRkzKguvAakJgbvvAD4J3AGsBH7g7ivM7CwzOys67F+BPzaz3wJ3Aee7+4a0bMoCmzblCUF3d/jNz3jrSZKMfji+oELUgnIFrTowIs3I3f1W4Na8sCWx9ReBv0jThqyxaRPssUcsIIs1AggZuzJ3IapP7r1atAjWrAk1gcWL6/q+pSoEoj+bNsH++8cCckKQpRqBECJdMlbQSrONQBSgXxtBzjWUtRqBEKJhkBDUmH5tBFl1DQkhGgYJQQ3p6YGtW/PaCLLYWCyEaCgkBDVk06bwqxqBECJLSAhqSEkhUI1ACFEnJAQ1ZPPm8KvGYiFElpAQ1JCiNYIRI2DkyLrYJIQQEoIakhOCfo3Fqg0IIeqIhKCGFK0RSAiEEHVEQlBDNm+G5mYYNy4W2N2thmIhRF2RENSQ3GAys1igagRCiDojIagh/UYVQxAC1QiEEHVEQlBD+s08CmosFkLUHQlBDSlaI5AQCCHqiISghvSbeRTUWCyEqDsSghqiGoEQIotICGrEjh3w+usF2gjUWCyEqDMSghrx2mvht6BrSDUCIUQdkRDUiIKjikGuISFE3ZEQ1IiCM4+6yzUkhKg7EoIaUbBGsHVr+FWNQAhRRyQENaLozKOgGoEQoq5ICGqEPlMphMgqEoIakWsj2K1GICEQQmQACUGN2LQJxo8PHyPbhVxDQogMICGoEUVHFYNqBEKIuiIhqBFFZx4F1QiEEHVFQlAjVCMQQmQVCUGNKDjzqIRACJEBJAQ1omCNQK4hIUQGkBDUAPcibQSqEQghMoCEoAZ0dYVpqFUjEEJkEQlBDSg44RyoRiCEyAQSghpQcgpqM2hpqblNQgiRI1UhMLOjzewpM3vGzL5Q5JgjzOwRM1thZj9L0556UVQIct8rNqu5TUIIkSM1ITCzZuAy4BhgDnCKmc3JO2YC8C1gvrsfCCxIy5560dkJJ50U1k85JWzvQh+lEUJkgDRrBIcCz7j7c+6+DbgeOD7vmFOBH7n7GgB3fzVFe2pOZycsXAgbNoTtl14K27vEIFcjEEKIOpKmEEwF1sa210VhcfYH9jCze8zsITP7q0IRmdlCM1tuZsvXr1+fkrnVZ9Givo5BObq7QzigGoEQIhOkKQSFHN+etz0CeCdwLPCXwJfMbP9+J7kvdfd57j5vypQp1be0inR2wsyZ0NQEq1cXPmbNmmhFNQIhRAYYUf6QAbMOmB7bnga8WOCYDe6+BdhiZj8HDgaeTtGuqtPZGUr5q1eHdl/Pl7s8ZsyIVlQjEEJkgDRrBA8C+5nZLDNrAU4Gbsk75mbgMDMbYWZtwLuBlSnaVJB4KX7mzLwG3QTnLlzYV/ovJwJtbbB4cbQhIRBCZIDUhMDddwCfBO4gZO4/cPcVZnaWmZ0VHbMSuB14DPg1cIW7P56WTYWIZ+Tu4feMM2Dy5D5hOOec4kJRqB2gEGbQ3g5Ll0JHRxQo15AQIgOYlyvCZox58+b58uXLqxbfzJnFffnFaGvry9CbmsrXAtrbYdWqAjsOOAAOPhi+//3KDBBCiAoxs4fcfV6hfWVrBGb2ATMbtiOQdzXcVkC850+/QWJ57OYKKhSRagRCiDqTJIM/GfidmV1kZrPTNqjWTJ9e/phCrF4dagMbN/YfGJzb7ucKykdtBEKIDFBWCNz9o8A7gGeBq83sl1G//nGpW5cS8cbhl18eeDw5l9CIETBpUl87wLXXhn2rVpUQAZAQCCEyQaLuo+7+ezO7ARgNfAb4IPD3ZvZ1d/9GivZVnVzjcK6Bd9u2IAh77NH38Zg33gjhSdm+HcaO7RtBnAh3uYaEEJkgSRvBcWZ2I3A3MBI41N2PIfT3/1zK9lWdQr18entDRt7bGzLzq64KJftcCf/ss/u2i1FxW8O2bUEMVCMQQtSZJDWCBcDX3P3n8UB37zazj6djVnoUy7Dj4R0dxV06xXoZ7RoklhR9lEYIkRGSNBb/E6GPPwBmNtrMZgK4+10p2ZUaxTLspBn54sX98+6SPYOKoY/SCCEyQhIh+CHQG9veGYUNSQabkXd0hJ5AcddRyZ5BxcjVCCQEQog6k8Q1NCKaRhoAd98WTRkxJMll2H/zN7BlS8jIFy+uLCMv5TpKTK5GINeQEKLOJBGC9WY2391vATCz44FK+sdkjo4O+PGP4Te/gafrNb2dXENCiIyQRAjOAjrN7JuEqaXXAgW/GzCUqHsXfjUWCyEyQlkhcPdngT8ys7GEuYneSN+s9OnpqXMerBqBECIjJBpQZmbHAgcCrRZ1pnf3f0nRrtTp7s5IjUBCIISoM0kGlC0BTgI+RXANLQDaU7YrdTJTI5BrSAhRZ5J0H/1jd/8rYLO7/zPwHnb/8tiQpO41ArmGhBAZIYkQbI1+u81sH2A7MCs9k2pD3WsEaiwWQmSEJG0EPzazCcBXgd8QPkB/eZpG1QLVCIQQIlBSCKIP0tzl7q8BN5jZT4BWd3+9FsalSWZqBK2tdTRCCCHKuIbcvRe4OLb95nAQgdwM0HWvEYweXXpKUyGEqAFJ2gjuNLMTzYZPjrV9e5hyuu69huQWEkJkgCRtBOcBY4AdZraV0IXU3X18qpalSCa68OujNEKIjJBkZPGQ/SRlMTLRTqsagRAiI5QVAjM7vFB4/odqhhKZGMtV90YKIYQIJHEN/X1svRU4FHgIODIVi2pAJlxDde+2JIQQgSSuoePi22Y2HbgoNYtqgGoEQgjRR5JeQ/msAw6qtiG1RDUCIYToI0kbwTcIo4khCMdc4NEUbUqdTNQI1FgshMgISdoIlsfWdwDfc/dfpGRPTchEjUCuISFERkgiBP8NbHX3nQBm1mxmbe7ena5p6ZGZGoFcQ0KIDJCkjeAuIF50HQ38NB1zaoNqBEII0UcSIWh1967cRrQ+pIuyg64RdHbCzJnQ1BR+OzuT7cs3QjUCIUQGSOIa2mJmh7j7bwDM7J1AT7pmpcvM+zt5nkVMnLIGZsyAxYuhoyPZyZ2dsHBhX7Vi9eqwnaPYvnj827fDzp2qEQghMkESIfgM8EMzezHa3pvw6cqhSWcnR/9oIS10h75QxTLrYixa1JfR5+juDuG59UL74nHrozRCiAxR1jXk7g8CBwBnA+cAs939obQNS41Fi2jZXiIjh9LunTVrCse7Zk3pfXEyMdmREEIEkny8/lxgjLs/7u6/Bcaa2Tnpm5YS5TLrnOtn9erw4YLVq+GMM2Dy5CAM7oXPnzEjLMX2xclEa7UQQgSSNBZ/IvpCGQDuvhn4RJLIzexoM3vKzJ4xsy+UOO5dZrbTzD6cJN5BUSyzbmoKy2mn9XfvbN8OGzcWF4G2ttDOsHgxjBy5+76WlhAeJxP9V4UQIpBECJriH6Uxs2agpdxJ0XGXAccAc4BTzGxOkeO+AtyR1OhBsXgxbzYXyIB37gwZ/c6dyeJpbg6/LS2wdGloAzj1VNhzzxBmFo7Zd9/+bQ9yDQkhMkQSIbgD+IGZHWVmRwLfA25LcN6hwDPu/py7bwOuB44vcNyngBuAVxPaPDg6OvjmwUvpbhoTtnMZeqX09sLXvgbbtsHBB4ewRx6BF16ASy8N+y+4AJ54Ap59dvdz1VgshMgQSYTgfMKgsrOBc4HH2H2AWTGmAmtj2+uisF2Y2VTgg8CSUhGZ2UIzW25my9evX5/g0qW5Y1IHv5xwDMyZEzLsgTBjRijpjxgBV18dwq69NtQGPvKRsH3GGUForrhi93NVIxBCZIgkvYZ6gQeA54B5wFHAygRxF/rGcb6T/RLg/Nz0FSVsWOru89x93pQpUxJcujQ9PTCWLhg7tnibQXNzcO9MmhQy9zi5NoEpU2D+/CAAPT1w3XVw7LEwcWI4burUUFu46KLdeyCpsVgIkSGKCoGZ7W9mXzazlcA3iUr37v4+d/9mgrjXAdNj29OAF/OOmQdcb2argA8D3zKzE5KbPzC6u2GMbwlCsHhxfxdNWxtcc02oLWzYAFddBe3tQRja2/vaBCCU+tevD20Dr7wC993X1920sxNWrAjx5HogLVwIP/1p33WEEKLOlBpQ9iRwL3Ccuz8DYGZ/V0HcDwL7mdks4AXgZODU+AHuPiu3bmbfAX7i7jdVcI0B0dMDbd4FY6b1ZeiLFoUupIVGGnd0FB9stnlz+O2KZuFYv75vgNqiRfDmm7sf390N118f1lUjEEJkgFJCcCIh8/4/M7ud0NhbyN1TEHffYWafJDQ2NwNXufsKMzsr2l+yXSBNenqgbWfkGoLSGX05vvSl/mG5AWrFxixs2hR+VSMQQmSAokLg7jcCN5rZGOAE4O+Avczsv4Ab3f3OcpG7+63ArXlhBQXA3U9Pbvbg6O6GUTu39AnBYCg1QG3GjOAOymfCBHjtNdUIhBCZIElj8RZ373T3DxD8/I8ARQeHDQV6eqB1RxeMGTP4yEqNJi7U/tDSAkceGdYlBEKIDFDRN4vdfZO7f9vdj0zLoFrQvcUZtb2rOjWCYo3NuXaGpUv7GppHjQrLlCnht2kgn4wWQojq0nA50fbtMKL3TZq8tzpCkJ/Z5/cq6uiAVatCz6H774c33oBvfzs0Ipf6XoEQQtSIJNNQDyu6u6MxBFAd1xAkb2xeuTKMT8hNY1HpFNhCCJECDVcj2DWYDKpTI6iERYv6z2WUPwW2EELUmIYTgu5uGMOWsFFrIUj6vQIhhKghDScEu9UIquUaSkrS7xUIIUQNaWwhqHWNoFQPIyGEqBMNJwR1dQ2V62EkhBB1oOF6DdXVNQSDm85CCCFSoCFrBHVzDQkhRAZpOCHo6amja0gIITJIwwlBKgPKhBBiCNNwQpBrI/DW1oF/r1gIIYYRDScEu3oNjZFbSAghoAGFoO97xXILCSEENKgQjG/qwtRQLIQQQAMKQXc3jG/aooZiIYSIaDgh6OmBcU1V+iiNEEIMAxpOCLq7YRwSAiGEyNFwQtDTA23INSSEEDkaTgi6u2GMq0YghBA5Gk4IenqgrVdCIIQQORpOCLq3OK075RoSQogcDScEvd1baaZXNQIhhIhoOCGwLZqCWggh4jScEDT1RFNQyzUkhBBAAwpBc49qBEIIEafhhGDEVgmBEELEaSgh2L4dRu2Ua0gIIeI0lBDs9uF61QiEEAKQEAghRMPTUEKw6+tkINeQEEJENJQQqEYghBD9aSgh6O6OCYFqBEIIAaQsBGZ2tJk9ZWbPmNkXCuzvMLPHouV+Mzs4TXt6eoJraGdLKzQ3p3kpIYQYMqQmBGbWDFwGHAPMAU4xszl5hz0P/Km7vx34V2BpWvZAn2uot01uISGEyJFmjeBQ4Bl3f87dtwHXA8fHD3D3+919c7T5ADAtRXt2uYYkBEII0UeaQjAVWBvbXheFFeNM4LZCO8xsoZktN7Pl69evH7BBOdcQbWofEEKIHGkKgRUI84IHmr2PIATnF9rv7kvdfZ67z5syZcqADdrVWDxONQIhhMgxIsW41wHTY9vTgBfzDzKztwNXAMe4+8YU7dnVRmDqOiqEELtIs0bwILCfmc0ysxbgZOCW+AFmNgP4EfAxd386RVuAvgFlTePlGhJCiByp1QjcfYeZfRK4A2gGrnL3FWZ2VrR/CfBlYBLwLTMD2OHu89KyKVcjaB6vGoEQQuRI0zWEu98K3JoXtiS2/tfAX6dpQ5xcG4GpjUAIIXbRUCOLd/Ua0qhiIYTYRUMJQfcWD72G1FgshBC7aCgh2NnVQxMuIRBCiBipthFkDe/SFNRCZJ3t27ezbt06tm7dWm9ThiStra1MmzaNkSNHJj6nsYTgDU1BLUTWWbduHePGjWPmzJlEvQlFQtydjRs3sm7dOmbNmpX4vIZyDTV1SwiEyDpbt25l0qRJEoEBYGZMmjSp4tpUQwkBW+QaEmIoIBEYOANJu4YSguYe1QiEECIfCYEQYkjT2QkzZ0JTU/jt7Bx8nM3NzcydO5eDDjqIBQsW0N3dXfTYe+65h/vvv3/X9k033cQTTzwxeCOK8PGPf5w999yTgw46qGpxNpQQjHhTriEhhhOdnbBwIaxeDe7hd+HCwYvB6NGjeeSRR3j88cdpaWlhyZIlRY+thhDs2LEj8bGnn346t99+e0Xxl6Oheg2NfFM1AiGGEp/5DDzySPH9DzwAb765e1h3N5x5Jlx+eeFz5s6FSy5JbsNhhx3GY489xo9//GMuvPBCtm3bxqRJk+js7KSnp4clS5bQ3NzMsmXLuPTSS7nlllv42c9+xoUXXsgNN9wAwLnnnsv69etpa2vj8ssv54ADDuD0009n4sSJPPzwwxxyyCFs3LiR8ePHs3z5cl5++WUuuugiPvzhD/ez5/DDD2fVqlXJbyABDSUELdskBEIMJ/JFoFx4pezYsYPbbruNo48+mve+97088MADmBlXXHEFF110ERdffDFnnXUWY8eO5XOf+xwA8+fP5wMf+MCuTPyoo45iyZIl7LfffvzqV7/inHPO4e677wbg6aef5qc//SnNzc2cfvrpvPTSS9x33308+eSTzJ8/v6AQpEHDCMGOHdDaG7mG2trqa4wQIhHlSu4zZwZ3UD7t7XDPPQO/bk9PD3PnzgVCjeDMM8/kqaee4qSTTuKll15i27Ztifrpd3V1cf/997NgwYJdYW/GVGrBggU0Nzfv2j7hhBNoampizpw5vPLKKwO/gQppGCHITUG9feRoRsYSXggxdFm8OLQJxNty29pC+GDItRHE+dSnPsV5553H/Pnzueeee7jgggvKxtPb28uECRP6xZVjTF575ahRo3atuxf8oGMqNExj8S4hGCW3kBDDhY4OWLo01ADMwu/SpSG82rz++utMnRo+u37NNdfsCh83bhxvvPFGwe3x48cza9YsfvjDHwIhc3/00Uerb9wgaRghyH2dbGeregwJMZzo6IBVq6C3N/ymIQIAF1xwAQsWLOCwww5j8uTJu8KPO+44brzxRubOncu9997LySefzFe/+lXe8Y538Oyzz9LZ2cmVV17JwQcfzIEHHsjNN988KDtOOeUU3vOe9/DUU08xbdo0rrzyysHeGlbL6kc1mDdvni9fvrzi81auhCfmnMhR059mwprfpmCZEKIarFy5ktmzZ9fbjCFNoTQ0s4eKfQGyoWoEY+mit02uISGEiNMQQtDZCcceG1xDjz83piojD4UQYrgw7HsN5UYe5moEq7ZPZuHCsC8tX6IQQgwlhn2NYNGivq5lY+mii7F0d4dwIYQQDSAEa9b0rY9hC1sY0y9cCCEamWEvBDNm9K3nagT54UII0cgMeyFYvDg3o4Qzhi10MbYqIw+FEBkhhXmoszoN9dq1a3nf+97H7NmzOfDAA7n00kurEu+wF4LcyMO3Te+hCadlwpjURh4KIWpMSvNQZ3Ua6hEjRnDxxRezcuVKHnjgAS677LKqiM6w7zUEIdPv+PMu2Au+uHgsSASEGBpkYB7qLE1Dvffee7P33nsDYSqL2bNn88ILLzBnzpzE91OIhhACALo0BbUQw46U56HO8jTUq1at4uGHH+bd7373oO+zcYRAH64XYuhRp3mosz4NdVdXFyeeeCKXXHIJ48ePH8Ad7k5jCEFnJ3z2s2H9nHNg61Y1EggxHEhpHuosT0O9fft2TjzxRDo6OvjQhz5U1oYkDPvG4l2NSTl1ffXV6nzUVAhRf2o4D3UWpqF2d84880xmz57NeeedN+B48hn+QhAfWpxDQ4uFGD7UaB7qLExD/Ytf/IJrr72Wu+++m7lz5zJ37lxuvfXWQd/b8J+GuqkpdCvLxyw8OEKITKFpqAePpqHOp9gQYg0tFkIIoBGEoG9ocR8aWiyEELsY/kJQy4+aCiGqwlBzWWeJgaRdqkJgZkeb2VNm9oyZfaHAfjOzr0f7HzOzQ1IxpFYfNRVCDJrW1lY2btwoMRgA7s7GjRtpbW2t6LzUxhGYWTNwGfDnwDrgQTO7xd3jE2McA+wXLe8G/iv6FUI0KNOmTWPdunWsX7++3qYMSVpbW5k2bVpF56Q5oOxQ4Bl3fw7AzK4HjgfiQnA88F0P0v+AmU0ws73d/aUU7RJCZJiRI0cmGrUrqkearqGpwNrY9roorNJjMLOFZrbczJarlCCEENUlTSGwAmH5Tr8kx+DuS919nrvPmzJlSlWME0IIEUhTCNYB02Pb04AXB3CMEEKIFEltZLGZjQCeBo4CXgAeBE519xWxY44FPgm8n9BI/HV3P7RMvOuBAtMNFmUysKEy62tCVu2C7NqWVbsgu7Zl1S7Irm1ZtQsGZ1u7uxd0qaTWWOzuO8zsk8AdQDNwlbuvMLOzov1LgFsJIvAM0A2ckSDeinxDZra82LDqepJVuyC7tmXVLsiubVm1C7JrW1btgvRsS3Uaane/lZDZx8OWxNYdODdNG4QQQpRm+I8sFkIIUZJGEIKl9TagCFm1C7JrW1btguzallW7ILu2ZdUuSMm2ITcNtRBCiOrSCDUCIYQQJZAQCCFEgzNshaDczKd1sGeVmf3WzB4xs+VR2EQz+18z+130u0cN7LjKzF41s8djYUXtMLMvRmn4lJn9ZR1su8DMXojS7REze3+tbTOz6Wb2f2a20sxWmNmno/C6plsJu7KQZq1m9mszezSy7Z+j8HqnWTG76p5mses1m9nDZvaTaDv9NHP3YbcQxi08C7wVaAEeBebU2aZVwOS8sIuAL0TrXwC+UgM7DgcOAR4vZwcwJ0q7UcCsKE2ba2zbBcDnChxbM9uAvYFDovVxhIGSc+qdbiXsykKaGTA2Wh8J/Ar4owykWTG76p5msWueB1wH/CTaTj3NhmuNYNfMp+6+DcjNfJo1jgeuidavAU5I+4Lu/nNgU0I7jgeud/c33f15wsC/kiO/U7CtGDWzzd1fcvffROtvACsJkyPWNd1K2FWMWqaZu3tXtDkyWpz6p1kxu4pR03fAzKYBxwJX5NmQapoNVyFINKtpjXHgTjN7yMwWRmF7eTTldvS7Z51sK2ZHVtLxkxY+XHRVrFpcF9vMbCbwDkJJMjPplmcXZCDNIhfHI8CrwP+6eybSrIhdkIE0Ay4BPg/0xsJST7PhKgSJZjWtMX/i7ocQPsZzrpkdXmd7kpCFdPwv4A+BucBLwMVReM1tM7OxwA3AZ9z996UOLRCWmm0F7MpEmrn7TnefS5hM8lAzO6jE4TWzrYhddU8zM/sA8Kq7P5T0lAJhA7JtuApB5mY1dfcXo99XgRsJVbhXzGxvgOj31TqZV8yOuqeju78Svbi9wOX0VX1rapuZjSRktp3u/qMouO7pVsiurKRZDnd/DbgHOJoMpFkhuzKSZn8CzDezVQR39pFmtowapNlwFYIHgf3MbJaZtQAnA7fUyxgzG2Nm43LrwF8Aj0c2nRYddhpwc30sLGrHLcDJZjbKzGYRPin661oalnsBIj5ISLea2mZmBlwJrHT3/4ztqmu6FbMrI2k2xcwmROujgT8DnqT+aVbQriykmbt/0d2nuftMQp51t7t/lFqkWZqt3/VcCLOaPk1oSV9UZ1veSmjdfxRYkbMHmATcBfwu+p1YA1u+R6j6bieUKM4sZQewKErDp4Bj6mDbtcBvgceiB3/vWtsGvJdQ5X4MeCRa3l/vdCthVxbS7O3Aw5ENjwNfLvfM1yjNitlV9zTLs/MI+noNpZ5mmmJCCCEanOHqGhJCCJEQCYEQQjQ4EgIhhGhwJARCCNHgSAiEEKLBkRAIkYeZ7YzNQvmIVXH2WjObabHZVYXIAql+vF6IIUqPhykIhGgIVCMQIiEWvinxlWg++1+b2b5ReLuZ3RVNWHaXmc2Iwvcysxujue8fNbM/jqJqNrPLo/nw74xGuApRNyQEQvRndJ5r6KTYvt+7+6HANwkzRRKtf9fd3w50Al+Pwr8O/MzdDyZ8Z2FFFL4fcJm7Hwi8BpyY6t0IUQaNLBYiDzPrcvexBcJXAUe6+3PRZG8vu/skM9tAmJJgexT+krtPNrP1wDR3fzMWx0zC1Mf7RdvnAyPd/cIa3JoQBVGNQIjK8CLrxY4pxJux9Z2orU7UGQmBEJVxUuz3l9H6/YTZIgE6gPui9buAs2HXx1DG18pIISpBJREh+jM6+oJVjtvdPdeFdJSZ/YpQiDolCvtb4Coz+3tgPXBGFP5pYKmZnUko+Z9NmF1ViEyhNgIhEhK1Ecxz9w31tkWIaiLXkBBCNDiqEQghRIOjGoEQQjQ4EgIhhGhwJARCCNHgSAiEEKLBkRAIIUSD8/8BIcw3Pvv9oOkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_intervals = range(5, 5 * (len(acc_a_list) + 1), 5) \n",
    "\n",
    "plt.plot(epoch_intervals, acc_a_list, label='Pattern 1', color='blue', marker='o') # 'marker' adds a marker at each data point\n",
    "plt.plot(epoch_intervals, acc_b_list, label='Pattern 2', color='red', marker='o') # 'marker' adds a marker at each data point\n",
    "\n",
    "# Adding legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Accuracy over epochs (5-layer)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "# Show the plot on the screen\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
